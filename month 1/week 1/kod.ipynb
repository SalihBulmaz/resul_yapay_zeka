{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Ay 1. Hafta - Pandas ile Veri ManipÃ¼lasyonu\n",
        "\n",
        "## ğŸ¯ Bu HaftanÄ±n Hedefleri\n",
        "- Pandas kÃ¼tÃ¼phanesinin temellerini Ã¶ÄŸrenmek\n",
        "- CSV dosyalarÄ±nÄ± okuma, yazma ve temel iÅŸlemler yapabilmek\n",
        "- Veri temizleme ve filtreleme tekniklerini kavramak\n",
        "- DataFrame ve Series yapÄ±larÄ±nÄ± etkili kullanabilmek\n",
        "\n",
        "## ğŸ“š Teorik Bilgiler\n",
        "\n",
        "### Pandas Nedir?\n",
        "Pandas (Python Data Analysis Library), veri analizi ve manipÃ¼lasyonu iÃ§in geliÅŸtirilmiÅŸ gÃ¼Ã§lÃ¼ bir Python kÃ¼tÃ¼phanesidir. Ä°ki ana veri yapÄ±sÄ± sunar:\n",
        "- **Series**: Tek boyutlu etiketli veri yapÄ±sÄ± (Excel'deki bir sÃ¼tun gibi)\n",
        "- **DataFrame**: Ä°ki boyutlu etiketli veri yapÄ±sÄ± (Excel tablosu gibi)\n",
        "\n",
        "### Neden Pandas?\n",
        "- Excel'den Ã§ok daha hÄ±zlÄ± ve gÃ¼Ã§lÃ¼\n",
        "- BÃ¼yÃ¼k veri setleriyle Ã§alÄ±ÅŸabilir (milyonlarca satÄ±r)\n",
        "- GeliÅŸmiÅŸ veri temizleme ve dÃ¶nÃ¼ÅŸtÃ¼rme araÃ§larÄ±\n",
        "- DiÄŸer Python kÃ¼tÃ¼phaneleri ile mÃ¼kemmel entegrasyon\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ› ï¸ Kurulum ve BaÅŸlangÄ±Ã§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri import etme\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Pandas versiyonunu kontrol etme\n",
        "print(f\"Pandas versiyonu: {pd.__version__}\")\n",
        "\n",
        "# GÃ¶rÃ¼ntÃ¼leme ayarlarÄ± (opsiyonel)\n",
        "pd.set_option('display.max_columns', None)  # TÃ¼m sÃ¼tunlarÄ± gÃ¶ster\n",
        "pd.set_option('display.width', None)        # GeniÅŸlik limiti kaldÄ±r\n",
        "pd.set_option('display.max_colwidth', 50)   # SÃ¼tun geniÅŸliÄŸi max 50 karakter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 1. GÃ¼n - Pandas Temelleri ve Veri YapÄ±larÄ±\n",
        "\n",
        "### Series OluÅŸturma ve Temel Ä°ÅŸlemler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Series oluÅŸturma - Liste ile\n",
        "sehirler = pd.Series(['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya'])\n",
        "print(\"Åehirler Series'i:\")\n",
        "print(sehirler)\n",
        "print(f\"Veri tipi: {type(sehirler)}\")\n",
        "\n",
        "# Series oluÅŸturma - Dictionary ile\n",
        "nufus = pd.Series({\n",
        "    'Ä°stanbul': 15519267,\n",
        "    'Ankara': 5663322,\n",
        "    'Ä°zmir': 4367251,\n",
        "    'Bursa': 3147818,\n",
        "    'Antalya': 2619832\n",
        "})\n",
        "print(\"\\nNÃ¼fus Series'i:\")\n",
        "print(nufus)\n",
        "\n",
        "# Series'ten belirli deÄŸerlere eriÅŸim\n",
        "print(f\"\\nÄ°stanbul nÃ¼fusu: {nufus['Ä°stanbul']:,}\")\n",
        "print(f\"Ä°lk 3 ÅŸehir:\\n{nufus.head(3)}\")\n",
        "print(f\"Son 2 ÅŸehir:\\n{nufus.tail(2)}\")\n",
        "\n",
        "# Temel istatistiksel bilgiler\n",
        "print(f\"\\nToplam nÃ¼fus: {nufus.sum():,}\")\n",
        "print(f\"Ortalama nÃ¼fus: {nufus.mean():,.0f}\")\n",
        "print(f\"En kalabalÄ±k ÅŸehir: {nufus.max():,}\")\n",
        "print(f\"En az nÃ¼fuslu ÅŸehir: {nufus.min():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataFrame OluÅŸturma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionary ile DataFrame oluÅŸturma\n",
        "sehir_bilgileri = {\n",
        "    'Åehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya'],\n",
        "    'NÃ¼fus': [15519267, 5663322, 4367251, 3147818, 2619832],\n",
        "    'BÃ¶lge': ['Marmara', 'Ä°Ã§ Anadolu', 'Ege', 'Marmara', 'Akdeniz'],\n",
        "    'Plaka_Kodu': [34, 6, 35, 16, 7],\n",
        "    'Denize_KÄ±yÄ±sÄ±': [True, False, True, False, True]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(sehir_bilgileri)\n",
        "print(\"Åehir Bilgileri DataFrame:\")\n",
        "print(df)\n",
        "print(f\"\\nDataFrame ÅŸekli: {df.shape}\")  # (satÄ±r, sÃ¼tun)\n",
        "print(f\"SÃ¼tun isimleri: {list(df.columns)}\")\n",
        "print(f\"Index: {list(df.index)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temel DataFrame Bilgileri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataFrame hakkÄ±nda genel bilgi\n",
        "print(\"DataFrame HakkÄ±nda Genel Bilgi:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nTemel Ä°statistikler:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nVeri Tipleri:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nNÃ¼fus sÃ¼tununun benzersiz deÄŸer sayÄ±sÄ±:\")\n",
        "print(df['NÃ¼fus'].nunique())\n",
        "\n",
        "print(\"\\nBÃ¶lgelerin benzersiz deÄŸerleri:\")\n",
        "print(df['BÃ¶lge'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 2. GÃ¼n - Veri Okuma ve Yazma Ä°ÅŸlemleri\n",
        "\n",
        "### CSV DosyasÄ± OluÅŸturma ve Okuma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–nce bir CSV dosyasÄ± oluÅŸturalÄ±m\n",
        "sample_data = {\n",
        "    'Ad': ['Ahmet', 'AyÅŸe', 'Mehmet', 'Fatma', 'Ali', 'Zeynep'],\n",
        "    'YaÅŸ': [25, 30, 35, 28, 32, 27],\n",
        "    'Åehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya', 'Ä°stanbul'],\n",
        "    'MaaÅŸ': [5000, 6500, 7200, 5800, 6200, 5500],\n",
        "    'Departman': ['IT', 'HR', 'IT', 'Muhasebe', 'IT', 'HR']\n",
        "}\n",
        "\n",
        "df_sample = pd.DataFrame(sample_data)\n",
        "\n",
        "# CSV dosyasÄ±na kaydetme\n",
        "df_sample.to_csv('calisanlar.csv', index=False, encoding='utf-8')\n",
        "print(\"CSV dosyasÄ± oluÅŸturuldu: calisanlar.csv\")\n",
        "\n",
        "# CSV dosyasÄ±nÄ± okuma\n",
        "df_read = pd.read_csv('calisanlar.csv', encoding='utf-8')\n",
        "print(\"\\nCSV dosyasÄ±ndan okunan veri:\")\n",
        "print(df_read)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FarklÄ± Okuma SeÃ§enekleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV okuma seÃ§enekleri\n",
        "# Belirli sÃ¼tunlarÄ± okuma\n",
        "df_selected = pd.read_csv('calisanlar.csv', usecols=['Ad', 'YaÅŸ', 'MaaÅŸ'])\n",
        "print(\"SeÃ§ili sÃ¼tunlar:\")\n",
        "print(df_selected)\n",
        "\n",
        "# Belirli satÄ±rlarÄ± okuma (nrows parametresi)\n",
        "df_limited = pd.read_csv('calisanlar.csv', nrows=3)\n",
        "print(\"\\nÄ°lk 3 satÄ±r:\")\n",
        "print(df_limited)\n",
        "\n",
        "# Index sÃ¼tunu belirleme\n",
        "df_indexed = pd.read_csv('calisanlar.csv', index_col='Ad')\n",
        "print(\"\\nAd sÃ¼tunu index olarak:\")\n",
        "print(df_indexed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Excel DosyasÄ± Ä°ÅŸlemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Excel dosyasÄ±na kaydetme\n",
        "df_sample.to_excel('calisanlar.xlsx', index=False)\n",
        "print(\"Excel dosyasÄ± oluÅŸturuldu: calisanlar.xlsx\")\n",
        "\n",
        "# Excel dosyasÄ±nÄ± okuma\n",
        "try:\n",
        "    df_excel = pd.read_excel('calisanlar.xlsx')\n",
        "    print(\"\\nExcel dosyasÄ±ndan okunan veri:\")\n",
        "    print(df_excel.head())\n",
        "except ImportError:\n",
        "    print(\"Excel okuma iÃ§in 'openpyxl' kÃ¼tÃ¼phanesi gerekli: pip install openpyxl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 3. GÃ¼n - Veri SeÃ§imi ve Filtreleme\n",
        "\n",
        "### SÃ¼tun SeÃ§imi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã‡alÄ±ÅŸanlar verisini kullanarak devam edelim\n",
        "df = pd.read_csv('calisanlar.csv')\n",
        "\n",
        "# Tek sÃ¼tun seÃ§imi (Series dÃ¶ner)\n",
        "yaÅŸlar = df['YaÅŸ']\n",
        "print(\"YaÅŸlar (Series):\")\n",
        "print(yaÅŸlar)\n",
        "print(f\"Tip: {type(yaÅŸlar)}\")\n",
        "\n",
        "# Tek sÃ¼tun seÃ§imi (DataFrame dÃ¶ner)\n",
        "yaÅŸlar_df = df[['YaÅŸ']]\n",
        "print(\"\\nYaÅŸlar (DataFrame):\")\n",
        "print(yaÅŸlar_df)\n",
        "print(f\"Tip: {type(yaÅŸlar_df)}\")\n",
        "\n",
        "# Birden fazla sÃ¼tun seÃ§imi\n",
        "kiÅŸi_bilgileri = df[['Ad', 'YaÅŸ', 'Åehir']]\n",
        "print(\"\\nKiÅŸi bilgileri:\")\n",
        "print(kiÅŸi_bilgileri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SatÄ±r SeÃ§imi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Index ile satÄ±r seÃ§imi\n",
        "print(\"Ä°lk satÄ±r (iloc ile):\")\n",
        "print(df.iloc[0])  # Series dÃ¶ner\n",
        "\n",
        "print(\"\\nÄ°lk satÄ±r (DataFrame olarak):\")\n",
        "print(df.iloc[[0]])  # DataFrame dÃ¶ner\n",
        "\n",
        "# Birden fazla satÄ±r seÃ§imi\n",
        "print(\"\\nÄ°lk 3 satÄ±r:\")\n",
        "print(df.iloc[0:3])\n",
        "\n",
        "# Son satÄ±r\n",
        "print(\"\\nSon satÄ±r:\")\n",
        "print(df.iloc[-1])\n",
        "\n",
        "# Belirli satÄ±rlar\n",
        "print(\"\\n1. ve 3. satÄ±rlar:\")\n",
        "print(df.iloc[[0, 2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### KoÅŸullu Filtreleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tek koÅŸul ile filtreleme\n",
        "genÃ§_Ã§alÄ±ÅŸanlar = df[df['YaÅŸ'] < 30]\n",
        "print(\"30 yaÅŸÄ±ndan kÃ¼Ã§Ã¼k Ã§alÄ±ÅŸanlar:\")\n",
        "print(genÃ§_Ã§alÄ±ÅŸanlar)\n",
        "\n",
        "# BÃ¼yÃ¼ktÃ¼r koÅŸulu\n",
        "yÃ¼ksek_maaÅŸlÄ± = df[df['MaaÅŸ'] > 6000]\n",
        "print(\"\\n6000'den fazla maaÅŸ alanlar:\")\n",
        "print(yÃ¼ksek_maaÅŸlÄ±)\n",
        "\n",
        "# String koÅŸulu\n",
        "istanbul_Ã§alÄ±ÅŸanlarÄ± = df[df['Åehir'] == 'Ä°stanbul']\n",
        "print(\"\\nÄ°stanbul'da Ã§alÄ±ÅŸanlar:\")\n",
        "print(istanbul_Ã§alÄ±ÅŸanlarÄ±)\n",
        "\n",
        "# Ä°Ã§erme koÅŸulu (isin)\n",
        "it_hr_Ã§alÄ±ÅŸanlarÄ± = df[df['Departman'].isin(['IT', 'HR'])]\n",
        "print(\"\\nIT ve HR departmanlarÄ±nda Ã§alÄ±ÅŸanlar:\")\n",
        "print(it_hr_Ã§alÄ±ÅŸanlarÄ±)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Birden Fazla KoÅŸul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VE (AND) koÅŸulu\n",
        "genÃ§_ve_yÃ¼ksek_maaÅŸlÄ± = df[(df['YaÅŸ'] < 30) & (df['MaaÅŸ'] > 5500)]\n",
        "print(\"GenÃ§ ve yÃ¼ksek maaÅŸlÄ± Ã§alÄ±ÅŸanlar:\")\n",
        "print(genÃ§_ve_yÃ¼ksek_maaÅŸlÄ±)\n",
        "\n",
        "# VEYA (OR) koÅŸulu\n",
        "istanbul_veya_ankara = df[(df['Åehir'] == 'Ä°stanbul') | (df['Åehir'] == 'Ankara')]\n",
        "print(\"\\nÄ°stanbul veya Ankara'da Ã§alÄ±ÅŸanlar:\")\n",
        "print(istanbul_veya_ankara)\n",
        "\n",
        "# DEÄÄ°L (NOT) koÅŸulu\n",
        "it_olmayan = df[~(df['Departman'] == 'IT')]\n",
        "print(\"\\nIT departmanÄ±nda olmayan Ã§alÄ±ÅŸanlar:\")\n",
        "print(it_olmayan)\n",
        "\n",
        "# KarmaÅŸÄ±k koÅŸul\n",
        "karmaÅŸÄ±k_filtre = df[\n",
        "    (df['YaÅŸ'] >= 25) & \n",
        "    (df['YaÅŸ'] <= 32) & \n",
        "    (df['MaaÅŸ'] > 5000) & \n",
        "    (df['Departman'].isin(['IT', 'HR']))\n",
        "]\n",
        "print(\"\\nKarmaÅŸÄ±k filtre sonucu:\")\n",
        "print(karmaÅŸÄ±k_filtre)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 4. GÃ¼n - Veri Temizleme ve Eksik Veri Ä°ÅŸleme\n",
        "\n",
        "### Eksik Veri OluÅŸturma ve Tespit Etme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eksik veriler iÃ§eren DataFrame oluÅŸturma\n",
        "import numpy as np\n",
        "\n",
        "eksik_veri = {\n",
        "    'Ad': ['Ahmet', 'AyÅŸe', 'Mehmet', None, 'Ali', 'Zeynep'],\n",
        "    'YaÅŸ': [25, None, 35, 28, 32, 27],\n",
        "    'Åehir': ['Ä°stanbul', 'Ankara', None, 'Bursa', 'Antalya', 'Ä°stanbul'],\n",
        "    'MaaÅŸ': [5000, 6500, 7200, None, 6200, 5500],\n",
        "    'Email': ['ahmet@email.com', None, 'mehmet@email.com', 'fatma@email.com', None, 'zeynep@email.com']\n",
        "}\n",
        "\n",
        "df_eksik = pd.DataFrame(eksik_veri)\n",
        "print(\"Eksik veriler iÃ§eren DataFrame:\")\n",
        "print(df_eksik)\n",
        "\n",
        "# Eksik verileri tespit etme\n",
        "print(\"\\nEksik veri kontrolÃ¼ (isnull):\")\n",
        "print(df_eksik.isnull())\n",
        "\n",
        "print(\"\\nEksik veri sayÄ±sÄ± (sÃ¼tunlara gÃ¶re):\")\n",
        "print(df_eksik.isnull().sum())\n",
        "\n",
        "print(\"\\nEksik veri yÃ¼zdesi:\")\n",
        "print((df_eksik.isnull().sum() / len(df_eksik)) * 100)\n",
        "\n",
        "# Eksik veri olan satÄ±rlarÄ± gÃ¶sterme\n",
        "print(\"\\nEksik veri iÃ§eren satÄ±rlarÄ±:\")\n",
        "eksik_satirlar = df_eksik[df_eksik.isnull().any(axis=1)]\n",
        "print(eksik_satirlar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eksik Veri Ä°ÅŸleme YÃ¶ntemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Eksik verileri silme\n",
        "print(\"1. Eksik verileri silme:\")\n",
        "\n",
        "# Herhangi bir sÃ¼tunda eksik veri olan satÄ±rlarÄ± silme\n",
        "df_temiz1 = df_eksik.dropna()\n",
        "print(f\"Orijinal satÄ±r sayÄ±sÄ±: {len(df_eksik)}\")\n",
        "print(f\"Temizleme sonrasÄ±: {len(df_temiz1)}\")\n",
        "print(df_temiz1)\n",
        "\n",
        "# Belirli sÃ¼tunlarda eksik veri olan satÄ±rlarÄ± silme\n",
        "df_temiz2 = df_eksik.dropna(subset=['Ad', 'YaÅŸ'])\n",
        "print(f\"\\nAd ve YaÅŸ sÃ¼tunlarÄ±nda eksik veri olmayan satÄ±rlar: {len(df_temiz2)}\")\n",
        "\n",
        "# 2. Eksik verileri doldurma\n",
        "print(\"\\n2. Eksik verileri doldurma:\")\n",
        "\n",
        "# Sabit deÄŸer ile doldurma\n",
        "df_doldurulmuÅŸ1 = df_eksik.fillna('Bilinmiyor')\n",
        "print(\"Sabit deÄŸer ile doldurma:\")\n",
        "print(df_doldurulmuÅŸ1)\n",
        "\n",
        "# SÃ¼tuna gÃ¶re farklÄ± deÄŸerler ile doldurma\n",
        "doldurma_deÄŸerleri = {\n",
        "    'Ad': 'Ä°simsiz',\n",
        "    'YaÅŸ': df_eksik['YaÅŸ'].mean(),  # Ortalama ile\n",
        "    'Åehir': 'Bilinmiyor',\n",
        "    'MaaÅŸ': df_eksik['MaaÅŸ'].median(),  # Medyan ile\n",
        "    'Email': 'email_yok@domain.com'\n",
        "}\n",
        "\n",
        "df_doldurulmuÅŸ2 = df_eksik.fillna(doldurma_deÄŸerleri)\n",
        "print(\"\\nSÃ¼tuna gÃ¶re farklÄ± deÄŸerler ile doldurma:\")\n",
        "print(df_doldurulmuÅŸ2)\n",
        "\n",
        "# Ä°leri/geri doldurma (forward fill / backward fill)\n",
        "df_ffill = df_eksik.fillna(method='ffill')  # Ã–nceki deÄŸer ile doldur\n",
        "print(\"\\nÃ–nceki deÄŸer ile doldurma (forward fill):\")\n",
        "print(df_ffill)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tekrarlanan Verileri Ä°ÅŸleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tekrarlanan veri oluÅŸturma\n",
        "tekrar_veri = {\n",
        "    'Ad': ['Ahmet', 'AyÅŸe', 'Mehmet', 'Ahmet', 'Ali', 'AyÅŸe'],\n",
        "    'YaÅŸ': [25, 30, 35, 25, 32, 30],\n",
        "    'Åehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Ä°stanbul', 'Antalya', 'Ankara']\n",
        "}\n",
        "\n",
        "df_tekrar = pd.DataFrame(tekrar_veri)\n",
        "print(\"Tekrarlanan veriler:\")\n",
        "print(df_tekrar)\n",
        "\n",
        "# Tekrarlanan satÄ±rlarÄ± tespit etme\n",
        "print(\"\\nTekrarlanan satÄ±rlar:\")\n",
        "print(df_tekrar.duplicated())\n",
        "\n",
        "print(\"\\nTekrarlanan satÄ±rlarÄ± gÃ¶sterme:\")\n",
        "print(df_tekrar[df_tekrar.duplicated()])\n",
        "\n",
        "# Tekrarlanan satÄ±rlarÄ± silme\n",
        "df_benzersiz = df_tekrar.drop_duplicates()\n",
        "print(f\"\\nOrijinal satÄ±r sayÄ±sÄ±: {len(df_tekrar)}\")\n",
        "print(f\"Tekrarlar silinince: {len(df_benzersiz)}\")\n",
        "print(df_benzersiz)\n",
        "\n",
        "# Belirli sÃ¼tunlara gÃ¶re tekrar kontrolÃ¼\n",
        "df_benzersiz_ad = df_tekrar.drop_duplicates(subset=['Ad'])\n",
        "print(\"\\nSadece 'Ad' sÃ¼tununa gÃ¶re benzersiz:\")\n",
        "print(df_benzersiz_ad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 5. GÃ¼n - Veri DÃ¶nÃ¼ÅŸtÃ¼rme ve Gruplama\n",
        "\n",
        "### SÃ¼tun Ä°ÅŸlemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Orijinal veriyi yeniden yÃ¼kleyelim\n",
        "df = pd.read_csv('calisanlar.csv')\n",
        "\n",
        "# Yeni sÃ¼tun ekleme\n",
        "df['YaÅŸ_Grubu'] = df['YaÅŸ'].apply(lambda x: 'GenÃ§' if x < 30 else 'Orta YaÅŸ' if x < 35 else 'Olgun')\n",
        "print(\"YaÅŸ grubu eklendi:\")\n",
        "print(df)\n",
        "\n",
        "# MaaÅŸ artÄ±ÅŸÄ± hesaplama\n",
        "df['Zam_SonrasÄ±_MaaÅŸ'] = df['MaaÅŸ'] * 1.15  # %15 zam\n",
        "print(f\"\\n%15 zam sonrasÄ± maaÅŸlar:\")\n",
        "print(df[['Ad', 'MaaÅŸ', 'Zam_SonrasÄ±_MaaÅŸ']])\n",
        "\n",
        "# String iÅŸlemleri\n",
        "df['Email'] = df['Ad'].str.lower() + '@company.com'\n",
        "print(f\"\\nEmail adresleri oluÅŸturuldu:\")\n",
        "print(df[['Ad', 'Email']])\n",
        "\n",
        "# Kategorik sÃ¼tun oluÅŸturma\n",
        "df['MaaÅŸ_Kategorisi'] = pd.cut(df['MaaÅŸ'], \n",
        "                               bins=[0, 5500, 6500, float('inf')], \n",
        "                               labels=['DÃ¼ÅŸÃ¼k', 'Orta', 'YÃ¼ksek'])\n",
        "print(f\"\\nMaaÅŸ kategorileri:\")\n",
        "print(df[['Ad', 'MaaÅŸ', 'MaaÅŸ_Kategorisi']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gruplama Ä°ÅŸlemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Departmana gÃ¶re gruplama\n",
        "print(\"Departmana gÃ¶re gruplama:\")\n",
        "dept_gruplarÄ± = df.groupby('Departman')\n",
        "\n",
        "# Her departmanÄ±n ortalama maaÅŸÄ±\n",
        "print(\"\\nDepartmanlarÄ±n ortalama maaÅŸlarÄ±:\")\n",
        "print(dept_gruplarÄ±['MaaÅŸ'].mean())\n",
        "\n",
        "# Her departmanÄ±n Ã§alÄ±ÅŸan sayÄ±sÄ±\n",
        "print(\"\\nDepartmanlarÄ±n Ã§alÄ±ÅŸan sayÄ±larÄ±:\")\n",
        "print(dept_gruplarÄ±.size())\n",
        "\n",
        "# Birden fazla istatistik\n",
        "print(\"\\nDepartmanlarÄ±n detaylÄ± istatistikleri:\")\n",
        "print(dept_gruplarÄ±['MaaÅŸ'].agg(['count', 'mean', 'min', 'max']))\n",
        "\n",
        "# Åehire gÃ¶re gruplama\n",
        "ÅŸehir_gruplarÄ± = df.groupby('Åehir')\n",
        "print(\"\\nÅehirlere gÃ¶re ortalama yaÅŸ:\")\n",
        "print(ÅŸehir_gruplarÄ±['YaÅŸ'].mean().sort_values(ascending=False))\n",
        "\n",
        "# Birden fazla sÃ¼tuna gÃ¶re gruplama\n",
        "karmaÅŸÄ±k_grup = df.groupby(['Åehir', 'Departman'])\n",
        "print(\"\\nÅehir ve departmana gÃ¶re gruplama:\")\n",
        "print(karmaÅŸÄ±k_grup['MaaÅŸ'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pivot Table Ä°ÅŸlemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot table oluÅŸturma\n",
        "pivot_table = df.pivot_table(\n",
        "    values='MaaÅŸ',\n",
        "    index='Åehir',\n",
        "    columns='Departman',\n",
        "    aggfunc='mean',\n",
        "    fill_value=0\n",
        ")\n",
        "print(\"Pivot Table - Åehir ve Departmana gÃ¶re ortalama maaÅŸlar:\")\n",
        "print(pivot_table)\n",
        "\n",
        "# Birden fazla deÄŸer ile pivot table\n",
        "pivot_table2 = df.pivot_table(\n",
        "    values=['MaaÅŸ', 'YaÅŸ'],\n",
        "    index='Departman',\n",
        "    aggfunc={'MaaÅŸ': 'mean', 'YaÅŸ': 'mean'}\n",
        ")\n",
        "print(\"\\nDepartmanlara gÃ¶re ortalama maaÅŸ ve yaÅŸ:\")\n",
        "print(pivot_table2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 6. GÃ¼n - SÄ±ralama ve Ä°ndeksleme\n",
        "\n",
        "### SÄ±ralama Ä°ÅŸlemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YaÅŸa gÃ¶re sÄ±ralama (artan)\n",
        "yaÅŸ_sÄ±ralÄ± = df.sort_values('YaÅŸ')\n",
        "print(\"YaÅŸa gÃ¶re artan sÄ±ralama:\")\n",
        "print(yaÅŸ_sÄ±ralÄ±[['Ad', 'YaÅŸ', 'MaaÅŸ']])\n",
        "\n",
        "# MaaÅŸa gÃ¶re sÄ±ralama (azalan)\n",
        "maaÅŸ_sÄ±ralÄ± = df.sort_values('MaaÅŸ', ascending=False)\n",
        "print(\"\\nMaaÅŸa gÃ¶re azalan sÄ±ralama:\")\n",
        "print(maaÅŸ_sÄ±ralÄ±[['Ad', 'YaÅŸ', 'MaaÅŸ']])\n",
        "\n",
        "# Birden fazla sÃ¼tuna gÃ¶re sÄ±ralama\n",
        "Ã§oklu_sÄ±ralama = df.sort_values(['Departman', 'MaaÅŸ'], ascending=[True, False])\n",
        "print(\"\\nDepartman (artan) ve MaaÅŸ (azalan) sÄ±ralamasÄ±:\")\n",
        "print(Ã§oklu_sÄ±ralama[['Ad', 'Departman', 'MaaÅŸ']])\n",
        "\n",
        "# Index'e gÃ¶re sÄ±ralama\n",
        "index_sÄ±ralÄ± = df.sort_index()\n",
        "print(\"\\nIndex'e gÃ¶re sÄ±ralama:\")\n",
        "print(index_sÄ±ralÄ±.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ä°ndeksleme Ä°ÅŸlemleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Index'i deÄŸiÅŸtirme\n",
        "df_new_index = df.set_index('Ad')\n",
        "print(\"Ad sÃ¼tunu index olarak ayarlandÄ±:\")\n",
        "print(df_new_index.head())\n",
        "\n",
        "# Index ile eriÅŸim\n",
        "print(f\"\\nAhmet'in bilgileri:\")\n",
        "print(df_new_index.loc['Ahmet'])\n",
        "\n",
        "# Ã‡oklu index oluÅŸturma\n",
        "df_multi_index = df.set_index(['Departman', 'Ad'])\n",
        "print(\"\\nÃ‡oklu index (Departman, Ad):\")\n",
        "print(df_multi_index)\n",
        "\n",
        "# Ã‡oklu index ile eriÅŸim\n",
        "print(f\"\\nIT departmanÄ±ndaki Ahmet'in bilgileri:\")\n",
        "print(df_multi_index.loc[('IT', 'Ahmet')])\n",
        "\n",
        "# Index'i sÄ±fÄ±rlama\n",
        "df_reset = df_new_index.reset_index()\n",
        "print(\"\\nIndex sÄ±fÄ±rlandÄ±:\")\n",
        "print(df_reset.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“Š 7. GÃ¼n - Pratik Uygulama ve Proje\n",
        "\n",
        "### KapsamlÄ± Veri Analizi Projesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daha bÃ¼yÃ¼k bir veri seti oluÅŸturalÄ±m\n",
        "import random\n",
        "np.random.seed(42)  # Tekrarlanabilir sonuÃ§lar iÃ§in\n",
        "\n",
        "# 100 Ã§alÄ±ÅŸan verisi oluÅŸturma\n",
        "n_Ã§alÄ±ÅŸan = 100\n",
        "Ã§alÄ±ÅŸan_verileri = {\n",
        "    'Ã‡alÄ±ÅŸan_ID': range(1, n_Ã§alÄ±ÅŸan + 1),\n",
        "    'Ad': [f'Ã‡alÄ±ÅŸan_{i}' for i in range(1, n_Ã§alÄ±ÅŸan + 1)],\n",
        "    'YaÅŸ': np.random.randint(22, 65, n_Ã§alÄ±ÅŸan),\n",
        "    'Departman': np.random.choice(['IT', 'HR', 'Muhasebe', 'Pazarlama', 'SatÄ±ÅŸ'], n_Ã§alÄ±ÅŸan),\n",
        "    'Åehir': np.random.choice(['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya'], n_Ã§alÄ±ÅŸan),\n",
        "    'Deneyim_YÄ±lÄ±': np.random.randint(0, 20, n_Ã§alÄ±ÅŸan),\n",
        "    'MaaÅŸ': np.random.randint(4000, 12000, n_Ã§alÄ±ÅŸan),\n",
        "    'Performans_PuanÄ±': np.random.randint(60, 100, n_Ã§alÄ±ÅŸan)\n",
        "}\n",
        "\n",
        "bÃ¼yÃ¼k_df = pd.DataFrame(Ã§alÄ±ÅŸan_verileri)\n",
        "\n",
        "# BazÄ± eksik veriler ekleyelim\n",
        "eksik_indeksler = np.random.choice(bÃ¼yÃ¼k_df.index, size=10, replace=False)\n",
        "bÃ¼yÃ¼k_df.loc[eksik_indeksler, 'Performans_PuanÄ±'] = np.nan\n",
        "\n",
        "print(\"BÃ¼yÃ¼k veri seti oluÅŸturuldu:\")\n",
        "print(f\"Veri seti boyutu: {bÃ¼yÃ¼k_df.shape}\")\n",
        "print(bÃ¼yÃ¼k_df.head())\n",
        "\n",
        "# Veriyi CSV'ye kaydetme\n",
        "bÃ¼yÃ¼k_df.to_csv('sirket_verileri.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Veri Analizi AdÄ±mlarÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Veri keÅŸfi\n",
        "print(\"=== VERÄ° KEÅFÄ° ===\")\n",
        "print(f\"Veri seti boyutu: {bÃ¼yÃ¼k_df.shape}\")\n",
        "print(f\"SÃ¼tun isimleri: {list(bÃ¼yÃ¼k_df.columns)}\")\n",
        "print(f\"Veri tipleri:\\n{bÃ¼yÃ¼k_df.dtypes}\")\n",
        "print(f\"\\nEksik veri sayÄ±sÄ±:\\n{bÃ¼yÃ¼k_df.isnull().sum()}\")\n",
        "\n",
        "# 2. Temel istatistikler\n",
        "print(\"\\n=== TEMEL Ä°STATÄ°STÄ°KLER ===\")\n",
        "print(bÃ¼yÃ¼k_df.describe())\n",
        "\n",
        "# 3. Eksik verileri iÅŸleme\n",
        "print(\"\\n=== EKSÄ°K VERÄ° Ä°ÅLEME ===\")\n",
        "bÃ¼yÃ¼k_df['Performans_PuanÄ±'].fillna(bÃ¼yÃ¼k_df['Performans_PuanÄ±'].mean(), inplace=True)\n",
        "print(f\"Eksik veriler doldurulduktan sonra: {bÃ¼yÃ¼k_df.isnull().sum()}\")\n",
        "\n",
        "# 4. Departman analizi\n",
        "print(\"\\n=== DEPARTMAN ANALÄ°ZÄ° ===\")\n",
        "dept_analiz = bÃ¼yÃ¼k_df.groupby('Departman').agg({\n",
        "    'MaaÅŸ': ['count', 'mean', 'min', 'max'],\n",
        "    'YaÅŸ': 'mean',\n",
        "    'Deneyim_YÄ±lÄ±': 'mean',\n",
        "    'Performans_PuanÄ±': 'mean'\n",
        "}).round(2)\n",
        "print(dept_analiz)\n",
        "\n",
        "# 5. Åehir analizi\n",
        "print(\"\\n=== ÅEHÄ°R ANALÄ°ZÄ° ===\")\n",
        "ÅŸehir_analiz = bÃ¼yÃ¼k_df.groupby('Åehir').agg({\n",
        "    'MaaÅŸ': 'mean',\n",
        "    'Ã‡alÄ±ÅŸan_ID': 'count'\n",
        "}).rename(columns={'Ã‡alÄ±ÅŸan_ID': 'Ã‡alÄ±ÅŸan_SayÄ±sÄ±'}).round(2)\n",
        "print(ÅŸehir_analiz.sort_values('MaaÅŸ', ascending=False))\n",
        "\n",
        "# 6. Korelasyon analizi\n",
        "print(\"\\n=== KORELASYON ANALÄ°ZÄ° ===\")\n",
        "korelasyon = bÃ¼yÃ¼k_df[['YaÅŸ', 'Deneyim_YÄ±lÄ±', 'MaaÅŸ', 'Performans_PuanÄ±']].corr()\n",
        "print(korelasyon.round(3))\n",
        "\n",
        "# 7. Filtreleme Ã¶rnekleri\n",
        "print(\"\\n=== FÄ°LTRELEME Ã–RNEKLERÄ° ===\")\n",
        "\n",
        "# YÃ¼ksek performanslÄ± Ã§alÄ±ÅŸanlar\n",
        "yÃ¼ksek_performans = bÃ¼yÃ¼k_df[bÃ¼yÃ¼k_df['Performans_PuanÄ±'] >= 90]\n",
        "print(f\"YÃ¼ksek performanslÄ± Ã§alÄ±ÅŸan sayÄ±sÄ±: {len(yÃ¼ksek_performans)}\")\n",
        "\n",
        "# IT departmanÄ±nda yÃ¼ksek maaÅŸlÄ± Ã§alÄ±ÅŸanlar\n",
        "it_yÃ¼ksek_maaÅŸ = bÃ¼yÃ¼k_df[\n",
        "    (bÃ¼yÃ¼k_df['Departman'] == 'IT') & \n",
        "    (bÃ¼yÃ¼k_df['MaaÅŸ'] > bÃ¼yÃ¼k_df['MaaÅŸ'].quantile(0.75))\n",
        "]\n",
        "print(f\"IT'de yÃ¼ksek maaÅŸlÄ± Ã§alÄ±ÅŸan sayÄ±sÄ±: {len(it_yÃ¼ksek_maaÅŸ)}\")\n",
        "\n",
        "# 8. SÄ±ralama ve en iyi/kÃ¶tÃ¼ Ã§alÄ±ÅŸanlar\n",
        "print(\"\\n=== SIRALAMA VE RANKING ===\")\n",
        "\n",
        "# En yÃ¼ksek maaÅŸlÄ± 5 Ã§alÄ±ÅŸan\n",
        "en_yÃ¼ksek_maaÅŸ = bÃ¼yÃ¼k_df.nlargest(5, 'MaaÅŸ')[['Ad', 'Departman', 'MaaÅŸ', 'Performans_PuanÄ±']]\n",
        "print(\"En yÃ¼ksek maaÅŸlÄ± 5 Ã§alÄ±ÅŸan:\")\n",
        "print(en_yÃ¼ksek_maaÅŸ)\n",
        "\n",
        "# En yÃ¼ksek performanslÄ± 5 Ã§alÄ±ÅŸan\n",
        "en_yÃ¼ksek_performans = bÃ¼yÃ¼k_df.nlargest(5, 'Performans_PuanÄ±')[['Ad', 'Departman', 'MaaÅŸ', 'Performans_PuanÄ±']]\n",
        "print(\"\\nEn yÃ¼ksek performanslÄ± 5 Ã§alÄ±ÅŸan:\")\n",
        "print(en_yÃ¼ksek_performans)\n",
        "\n",
        "# 9. Pivot table analizi\n",
        "print(\"\\n=== PIVOT TABLE ANALÄ°ZÄ° ===\")\n",
        "pivot_analiz = bÃ¼yÃ¼k_df.pivot_table(\n",
        "    values=['MaaÅŸ', 'Performans_PuanÄ±'],\n",
        "    index='Departman',\n",
        "    columns='Åehir',\n",
        "    aggfunc='mean',\n",
        "    fill_value=0\n",
        ").round(2)\n",
        "print(\"Departman ve Åehire gÃ¶re ortalama maaÅŸ ve performans:\")\n",
        "print(pivot_analiz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ã–zel Analiz FonksiyonlarÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veri analizi iÃ§in Ã¶zel fonksiyonlar oluÅŸturalÄ±m\n",
        "\n",
        "def yaÅŸ_grubu_oluÅŸtur(yaÅŸ):\n",
        "    \"\"\"YaÅŸa gÃ¶re grup belirleme fonksiyonu\"\"\"\n",
        "    if yaÅŸ < 25:\n",
        "        return 'GenÃ§'\n",
        "    elif yaÅŸ < 35:\n",
        "        return 'Orta YaÅŸ'\n",
        "    elif yaÅŸ < 50:\n",
        "        return 'Orta YaÅŸ ÃœstÃ¼'\n",
        "    else:\n",
        "        return 'Olgun'\n",
        "\n",
        "def maaÅŸ_kategorisi_oluÅŸtur(maaÅŸ):\n",
        "    \"\"\"MaaÅŸa gÃ¶re kategori belirleme fonksiyonu\"\"\"\n",
        "    if maaÅŸ < 5000:\n",
        "        return 'DÃ¼ÅŸÃ¼k'\n",
        "    elif maaÅŸ < 7500:\n",
        "        return 'Orta'\n",
        "    elif maaÅŸ < 10000:\n",
        "        return 'YÃ¼ksek'\n",
        "    else:\n",
        "        return 'Ã‡ok YÃ¼ksek'\n",
        "\n",
        "def performans_deÄŸerlendirme(puan):\n",
        "    \"\"\"Performans puanÄ±na gÃ¶re deÄŸerlendirme\"\"\"\n",
        "    if puan < 70:\n",
        "        return 'GeliÅŸim Gerekli'\n",
        "    elif puan < 80:\n",
        "        return 'Ortalama'\n",
        "    elif puan < 90:\n",
        "        return 'Ä°yi'\n",
        "    else:\n",
        "        return 'MÃ¼kemmel'\n",
        "\n",
        "# FonksiyonlarÄ± uygulama\n",
        "bÃ¼yÃ¼k_df['YaÅŸ_Grubu'] = bÃ¼yÃ¼k_df['YaÅŸ'].apply(yaÅŸ_grubu_oluÅŸtur)\n",
        "bÃ¼yÃ¼k_df['MaaÅŸ_Kategorisi'] = bÃ¼yÃ¼k_df['MaaÅŸ'].apply(maaÅŸ_kategorisi_oluÅŸtur)\n",
        "bÃ¼yÃ¼k_df['Performans_DeÄŸerlendirme'] = bÃ¼yÃ¼k_df['Performans_PuanÄ±'].apply(performans_deÄŸerlendirme)\n",
        "\n",
        "print(\"Yeni kategorik sÃ¼tunlar eklendi:\")\n",
        "print(bÃ¼yÃ¼k_df[['Ad', 'YaÅŸ_Grubu', 'MaaÅŸ_Kategorisi', 'Performans_DeÄŸerlendirme']].head())\n",
        "\n",
        "# Kategorik analiz\n",
        "print(\"\\n=== KATEGORÄ°K ANALÄ°Z ===\")\n",
        "print(\"YaÅŸ grubu daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(bÃ¼yÃ¼k_df['YaÅŸ_Grubu'].value_counts())\n",
        "\n",
        "print(\"\\nMaaÅŸ kategorisi daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(bÃ¼yÃ¼k_df['MaaÅŸ_Kategorisi'].value_counts())\n",
        "\n",
        "print(\"\\nPerformans deÄŸerlendirme daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(bÃ¼yÃ¼k_df['Performans_DeÄŸerlendirme'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ä°leri Seviye Veri ManipÃ¼lasyonu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã‡oklu koÅŸullu filtreleme ve seÃ§im\n",
        "print(\"\\n=== Ä°LERÄ° SEVÄ°YE FÄ°LTRELEME ===\")\n",
        "\n",
        "# Lambda fonksiyonu ile karmaÅŸÄ±k filtreleme\n",
        "yÃ¼ksek_potansiyel = bÃ¼yÃ¼k_df[\n",
        "    bÃ¼yÃ¼k_df.apply(lambda row: \n",
        "        (row['YaÅŸ'] < 35) and \n",
        "        (row['Performans_PuanÄ±'] >= 85) and \n",
        "        (row['Deneyim_YÄ±lÄ±'] >= 3), axis=1)\n",
        "]\n",
        "print(f\"YÃ¼ksek potansiyelli genÃ§ Ã§alÄ±ÅŸan sayÄ±sÄ±: {len(yÃ¼ksek_potansiyel)}\")\n",
        "\n",
        "# Quantile tabanlÄ± analiz\n",
        "print(\"\\n=== QUANTÄ°LE ANALÄ°ZÄ° ===\")\n",
        "maaÅŸ_quantiles = bÃ¼yÃ¼k_df['MaaÅŸ'].quantile([0.25, 0.5, 0.75, 0.9, 0.95])\n",
        "print(\"MaaÅŸ daÄŸÄ±lÄ±mÄ± (percentile):\")\n",
        "for q, deÄŸer in maaÅŸ_quantiles.items():\n",
        "    print(f\"%{int(q*100)}: {deÄŸer:,.0f} TL\")\n",
        "\n",
        "# En yÃ¼ksek %10'luk dilim\n",
        "top_10_percent = bÃ¼yÃ¼k_df[bÃ¼yÃ¼k_df['MaaÅŸ'] >= bÃ¼yÃ¼k_df['MaaÅŸ'].quantile(0.9)]\n",
        "print(f\"\\nEn yÃ¼ksek %10'luk dilimde {len(top_10_percent)} Ã§alÄ±ÅŸan var\")\n",
        "\n",
        "# String iÅŸlemleri ve regex\n",
        "print(\"\\n=== STRING Ä°ÅLEMLERÄ° ===\")\n",
        "# Email adresleri oluÅŸturma\n",
        "bÃ¼yÃ¼k_df['Email'] = (bÃ¼yÃ¼k_df['Ad'].str.lower().str.replace('_', '.') + \n",
        "                     '@' + \n",
        "                     bÃ¼yÃ¼k_df['Departman'].str.lower() + \n",
        "                     '.company.com')\n",
        "\n",
        "print(\"Ã–rnek email adresleri:\")\n",
        "print(bÃ¼yÃ¼k_df[['Ad', 'Departman', 'Email']].head())\n",
        "\n",
        "# SÃ¼tun adlarÄ±nÄ± temizleme\n",
        "bÃ¼yÃ¼k_df.columns = bÃ¼yÃ¼k_df.columns.str.lower().str.replace('_', ' ')\n",
        "print(f\"\\nTemizlenmiÅŸ sÃ¼tun adlarÄ±: {list(bÃ¼yÃ¼k_df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Veri DÄ±ÅŸa Aktarma ve Raporlama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã–zet rapor oluÅŸturma\n",
        "print(\"\\n=== Ã–ZET RAPOR ===\")\n",
        "\n",
        "rapor = {\n",
        "    'Toplam Ã‡alÄ±ÅŸan': len(bÃ¼yÃ¼k_df),\n",
        "    'Ortalama YaÅŸ': bÃ¼yÃ¼k_df['yaÅŸ'].mean(),\n",
        "    'Ortalama MaaÅŸ': bÃ¼yÃ¼k_df['maaÅŸ'].mean(),\n",
        "    'Ortalama Deneyim': bÃ¼yÃ¼k_df['deneyim yÄ±lÄ±'].mean(),\n",
        "    'Ortalama Performans': bÃ¼yÃ¼k_df['performans puanÄ±'].mean(),\n",
        "    'En KalabalÄ±k Departman': bÃ¼yÃ¼k_df['departman'].mode()[0],\n",
        "    'En KalabalÄ±k Åehir': bÃ¼yÃ¼k_df['ÅŸehir'].mode()[0]\n",
        "}\n",
        "\n",
        "print(\"Åirket Genel Durumu:\")\n",
        "for anahtar, deÄŸer in rapor.items():\n",
        "    if isinstance(deÄŸer, (int, float)) and not isinstance(deÄŸer, bool):\n",
        "        print(f\"{anahtar}: {deÄŸer:.2f}\")\n",
        "    else:\n",
        "        print(f\"{anahtar}: {deÄŸer}\")\n",
        "\n",
        "# Departman bazlÄ± detaylÄ± rapor\n",
        "dept_rapor = bÃ¼yÃ¼k_df.groupby('departman').agg({\n",
        "    'Ã§alÄ±ÅŸan id': 'count',\n",
        "    'maaÅŸ': ['mean', 'min', 'max'],\n",
        "    'yaÅŸ': 'mean',\n",
        "    'performans puanÄ±': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nDepartman BazlÄ± Rapor:\")\n",
        "print(dept_rapor)\n",
        "\n",
        "# Veriyi farklÄ± formatlarda kaydetme\n",
        "bÃ¼yÃ¼k_df.to_csv('analiz_sonucu.csv', index=False)\n",
        "bÃ¼yÃ¼k_df.to_excel('analiz_sonucu.xlsx', index=False)\n",
        "\n",
        "# Sadece Ã¶zet istatistikleri kaydetme\n",
        "Ã¶zet_df = bÃ¼yÃ¼k_df.groupby('departman').agg({\n",
        "    'maaÅŸ': ['count', 'mean', 'std'],\n",
        "    'performans puanÄ±': 'mean'\n",
        "}).round(2)\n",
        "Ã¶zet_df.to_csv('departman_ozeti.csv')\n",
        "\n",
        "print(\"\\nDosyalar kaydedildi:\")\n",
        "print(\"- analiz_sonucu.csv\")\n",
        "print(\"- analiz_sonucu.xlsx\") \n",
        "print(\"- departman_ozeti.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ¯ Hafta Sonu DeÄŸerlendirmesi\n",
        "\n",
        "### Bu Hafta Ã–ÄŸrendikleriniz\n",
        "\n",
        "1. **Pandas Temelleri**\n",
        "   - Series ve DataFrame yapÄ±larÄ±\n",
        "   - Veri okuma/yazma iÅŸlemleri\n",
        "   - Temel indeksleme ve seÃ§im\n",
        "\n",
        "2. **Veri Temizleme**\n",
        "   - Eksik veri tespiti ve iÅŸleme\n",
        "   - Tekrarlanan veri kontrolÃ¼\n",
        "   - Veri tiplerini anlama\n",
        "\n",
        "3. **Veri ManipÃ¼lasyonu**\n",
        "   - Filtreleme ve koÅŸullu seÃ§im\n",
        "   - Gruplama ve agregasyon\n",
        "   - SÄ±ralama ve indeksleme\n",
        "\n",
        "4. **Ä°leri Seviye Ä°ÅŸlemler**\n",
        "   - Pivot table oluÅŸturma\n",
        "   - Lambda fonksiyonlarÄ±\n",
        "   - String iÅŸlemleri\n",
        "\n",
        "### Pratik Egzersizleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EGZERSIZ 1: Kendi veri setinizi oluÅŸturun\n",
        "# 50 Ã¶ÄŸrenci bilgisi iÃ§eren bir DataFrame oluÅŸturun:\n",
        "# - Ad, Soyad, YaÅŸ, BÃ¶lÃ¼m, Not OrtalamasÄ±, Åehir\n",
        "\n",
        "# EGZERSIZ 2: Veri analizi yapÄ±n\n",
        "# - BÃ¶lÃ¼mlere gÃ¶re ortalama not hesaplayan\n",
        "# - En baÅŸarÄ±lÄ± 10 Ã¶ÄŸrenciyi bulan\n",
        "# - Åehirlere gÃ¶re Ã¶ÄŸrenci daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steren kod yazÄ±n\n",
        "\n",
        "# EGZERSIZ 3: Veri temizleme\n",
        "# Veri setinize bilinÃ§li olarak eksik veriler ekleyin ve bunlarÄ± farklÄ± yÃ¶ntemlerle temizleyin\n",
        "\n",
        "print(\"=== HAFTA SONU EGZERSÄ°ZLERÄ° ===\")\n",
        "print(\"YukarÄ±daki egzersizleri Ã§Ã¶zerek bu haftaki Ã¶ÄŸrendiklerinizi pekiÅŸtirin!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gelecek Hafta HazÄ±rlÄ±ÄŸÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gelecek hafta iÃ§in hazÄ±rlÄ±k\n",
        "print(\"=== GELECEK HAFTA Ä°Ã‡Ä°N HAZIRLIK ===\")\n",
        "print(\"Åu konularÄ± tekrar edin:\")\n",
        "print(\"1. DataFrame oluÅŸturma ve temel iÅŸlemler\")\n",
        "print(\"2. Filtreleme ve koÅŸullu seÃ§im\")\n",
        "print(\"3. Gruplama ve agregasyon\")\n",
        "print(\"4. Veri temizleme teknikleri\")\n",
        "print(\"\\nGelecek hafta NumPy ile matematiksel iÅŸlemler Ã¶ÄŸreneceÄŸiz!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“– Ek Kaynaklar ve Referanslar\n",
        "\n",
        "### Video EÄŸitim Ã–nerileri\n",
        "1. **Corey Schafer - Pandas Tutorials** (YouTube)\n",
        "2. **Data School - Pandas** (YouTube)\n",
        "3. **Kaggle Learn - Pandas Course**\n",
        "\n",
        "### DokÃ¼mantasyon\n",
        "- [Pandas Official Documentation](https://pandas.pydata.org/docs/)\n",
        "- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
        "\n",
        "### Pratik Ä°Ã§in Veri Setleri\n",
        "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
        "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
        "- [TÃœÄ°K Veri Setleri](https://www.tuik.gov.tr/)\n",
        "\n",
        "### Ä°puÃ§larÄ±\n",
        "- Her gÃ¼n en az 1 saat pratik yapÄ±n\n",
        "- GerÃ§ek veri setleri ile Ã§alÄ±ÅŸÄ±n\n",
        "- Hata mesajlarÄ±nÄ± okuyun ve anlamaya Ã§alÄ±ÅŸÄ±n\n",
        "- Stack Overflow ve GitHub'da Ã¶rnekleri inceleyin\n",
        "\n",
        "**BaÅŸarÄ±lar! ğŸš€**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
